{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import html\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "codice_galattico = \"../Hackapizza Dataset/Codice Galattico/Codice Galattico.pdf\"\n",
    "manuale_cucina = \"../Hackapizza Dataset/Misc/Manuale di Cucina.pdf\"\n",
    "menu_esempio = \"../Hackapizza Dataset/Menu/Anima Cosmica.pdf\"\n",
    "\n",
    "domande = \"../Hackapizza Dataset/domande.csv\"\n",
    "piatti = \"../Hackapizza Dataset/Misc/dish_mapping.json\"\n",
    "pianeti = \"../Hackapizza Dataset/Misc/Distanze.csv\"\n",
    "\n",
    "blog_1 = \"../Hackapizza Dataset/Blogpost/blog_etere_del_gusto.html\"\n",
    "blog_2 = \"../Hackapizza Dataset/Blogpost/blog_sapore_del_dune.html\"\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "# Recupera endpoint e chiave dalle variabili d'ambiente\n",
    "api_base = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# neo4j first instance parameters\n",
    "NEO4J_URI= \"neo4j+s://0482640f.databases.neo4j.io\"\n",
    "NEO4J_USERNAME= \"neo4j\"\n",
    "NEO4J_PASSWORD= \"PNvdaZlk326-ja2hRD1K97ZUUMnD4mj0NsecZNu5-9k\"\n",
    "AURA_INSTANCEID= \"0482640f\"\n",
    "AURA_INSTANCENAME= \"Instance01\"\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_llm(api_key: str, api_base: str) -> AzureChatOpenAI:\n",
    "    \"\"\"\n",
    "    Crea un'istanza del modello linguistico Azure OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        api_key (str): La chiave API di Azure\n",
    "        api_base (str): L'URL base dell'API Azure\n",
    "        \n",
    "    Returns:\n",
    "        AzureChatOpenAI: Istanza configurata del modello\n",
    "    \"\"\"\n",
    "    return AzureChatOpenAI(\n",
    "        openai_api_version=\"2024-08-01-preview\",\n",
    "        azure_deployment=\"o1-mini\",\n",
    "        azure_endpoint=api_base,\n",
    "        api_key=api_key,\n",
    "        temperature=1\n",
    "    )\n",
    "\n",
    "llm = crea_llm(api_key, api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrai_testo_pdf(percorso_pdf):\n",
    "    with open(percorso_pdf, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        testo = \"\"\n",
    "        for pagina in reader.pages:\n",
    "            testo += pagina.extract_text()\n",
    "    return testo\n",
    "\n",
    "def estrai_testo_html(percorso_html):\n",
    "    \"\"\"Estrae il testo da un file HTML.\"\"\"\n",
    "    with open(percorso_html, \"r\", encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, \"html.parser\")\n",
    "        return soup.get_text(separator=\" \", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrai_relazioni(testo, categorie, llm):\n",
    "    \n",
    "    # Prompt migliorato per il modello AI\n",
    "    prompt = f\"\"\"\n",
    "    Contesto: questo testo rientra in una collezione di documenti che parlano di Ristoranti nello spazio (su Pianeti) e sui loro Menu, Piatti, Ingredienti e Tecniche. \n",
    "    \n",
    "    Mi serve che analizzi il testo e identifichi le RELAZIONI che legano le seguenti CATEGORIE all'interno del testo.\n",
    "    \n",
    "    Esempi di relazioni sono: DISTANTE, CONTIENE, PREPARATO \n",
    "\n",
    "    CATEGORIE: {categorie}\n",
    "\n",
    "    Una relazione può essere tra una coppia di categorie o tra una categoria e se stessa.\n",
    "\n",
    "    Voglio che mi ritorni un JSON con:\n",
    "    - La chiave che indica il nome della relazione, che deve essere una SINGOLA PAROLA\n",
    "    - La lista delle cateogire coinvolte nella relazione: una relazione può essere tra una coppia di categorie o tra una categoria e se stessa.\n",
    "\n",
    "    Restituisci SOLO il JSON, senza formattazione markdown o decoratori.\n",
    "\n",
    "    Testo:\n",
    "    {testo}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    content = response.content.strip()\n",
    "\n",
    "    # Pulizia del JSON\n",
    "    if content.startswith('```') and content.endswith('```'):\n",
    "        content = '\\n'.join(content.split('\\n')[1:-1])\n",
    "    if content.startswith('json'):\n",
    "        content = content[4:].strip()\n",
    "\n",
    "    try:\n",
    "        sostanze = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Errore nel parsing JSON delle sostanze:\", content)\n",
    "        sostanze = {}\n",
    "\n",
    "    return sostanze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combina_punteggi(json_list, llm):\n",
    "    \"\"\"Combina i punteggi delle entità da più JSON, normalizzando sinonimi tramite LLM.\"\"\"\n",
    "    punteggi_totali = {}\n",
    "    conteggio = {}\n",
    "    \n",
    "    for entita_manuale in json_list:\n",
    "        for entita, punteggio in entita_manuale.items():\n",
    "            if entita in punteggi_totali:\n",
    "                punteggi_totali[entita] += punteggio\n",
    "                conteggio[entita] += 1\n",
    "            else:\n",
    "                punteggi_totali[entita] = punteggio\n",
    "                conteggio[entita] = 1\n",
    "    \n",
    "    punteggi_medi = {entita: punteggi_totali[entita] / conteggio[entita] for entita in punteggi_totali}\n",
    "    \n",
    "    # Normalizzazione con LLM\n",
    "    prompt = f\"\"\"\n",
    "    Data la seguente lista di categoria con punteggi, RAGGRUPPA SINONIMI e parole che hanno circa lo stesso significato sotto un'unica categoria (che deve essere una SINGOLA PAROLA).\n",
    "    Restituisci il risultato come JSON con le categorie normalizzate e i punteggi medi aggregati.\n",
    "    Restituisci SOLO il JSON, senza formattazione markdown o decoratori.\n",
    "    \n",
    "    {json.dumps(punteggi_medi, indent=2, ensure_ascii=False)}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    content = response.content.strip()\n",
    "\n",
    "    # Pulizia del JSON\n",
    "    if content.startswith('```') and content.endswith('```'):\n",
    "        content = '\\n'.join(content.split('\\n')[1:-1])\n",
    "    if content.startswith('json'):\n",
    "        content = content[4:].strip()\n",
    "\n",
    "    try:\n",
    "        sostanze = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Errore nel parsing JSON delle sostanze:\", content)\n",
    "        sostanze = {}\n",
    "\n",
    "    return sostanze\n",
    "    #entita_normalizzate = json.loads(response.strip())\n",
    "    #return dict(sorted(entita_normalizzate.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tecnica', 'Licenza', 'Ordine', 'Ingrediente', 'Piatto', 'Ristorante', 'Pianeta']\n"
     ]
    }
   ],
   "source": [
    "with open('entita_filtrate.txt', 'r', encoding='utf-8') as file:\n",
    "    entita_filtrate = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "print(entita_filtrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità CSV: {'CONTIENE': ['Piatto', 'Ingrediente'], 'PREPARATO': ['Piatto', 'Tecnica'], 'OFFERTA': ['Ristorante', 'Piatto'], 'SITUATO': ['Ristorante', 'Pianeta'], 'RICHIEDE': ['Piatto', 'Licenza'], 'APPARTIENE': ['Ordine', 'Piatto']}\n"
     ]
    }
   ],
   "source": [
    "# Carica il file CSV\n",
    "df_domande = pd.read_csv(domande)\n",
    "testo_domande = df_domande.to_string()  # Converti il CSV in testo\n",
    "entita_domande = estrai_relazioni(testo=testo_domande, categorie=entita_filtrate, llm=llm)\n",
    "print(\"Entità CSV:\", entita_domande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità CSV: {'DISTANTE': ['Pianeta', 'Pianeta']}\n"
     ]
    }
   ],
   "source": [
    "# Carica il file CSV\n",
    "df_pianeti = pd.read_csv(pianeti)\n",
    "testo_pianeti = df_pianeti.to_string()  # Converti il CSV in testo\n",
    "entita_pianeti = estrai_relazioni(testo=testo_pianeti, categorie=entita_filtrate, llm=llm)\n",
    "print(\"Entità CSV:\", entita_pianeti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità PDF: {'utilizza': ['Tecnica', 'Ingrediente'], 'prepara': ['Tecnica', 'Piatto'], 'contiene': ['Piatto', 'Ingrediente'], 'situato': ['Ristorante', 'Pianeta'], 'serve': ['Ristorante', 'Piatto'], 'richiede': ['Tecnica', 'Licenza'], 'appartiene_piatto_ord': ['Piatto', 'Ordine'], 'appartiene_ristorante_ord': ['Ristorante', 'Ordine'], 'regola': ['Ordine', 'Licenza'], 'implementa': ['Ordine', 'Tecnica'], 'influenzato': ['Piatto', 'Pianeta']}\n"
     ]
    }
   ],
   "source": [
    "# Esegui l'analisi del PDF\n",
    "testo_manuale = estrai_testo_pdf(manuale_cucina)\n",
    "entita_manuale = estrai_relazioni(testo=testo_manuale, categorie=entita_filtrate, llm=llm)\n",
    "print(\"Entità PDF:\", entita_manuale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità PDF: {'requires': ['Tecnica', 'Licenza'], 'belongs_to': ['Ordine', 'Pianeta'], 'prepares': ['Tecnica', 'Piatto'], 'located_on': ['Ristorante', 'Pianeta'], 'contains': ['Piatto', 'Ingrediente'], 'regulated_by': ['Ingrediente', 'Licenza'], 'implements': ['Ristorante', 'Tecnica'], 'follows': ['Ordine', 'Tecnica']}\n"
     ]
    }
   ],
   "source": [
    "# Esegui l'analisi del PDF\n",
    "testo_codice = estrai_testo_pdf(codice_galattico)\n",
    "entita_codice = estrai_relazioni(testo=testo_codice, categorie=entita_filtrate, llm=llm)\n",
    "print(\"Entità PDF:\", entita_codice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità PDF: {'contiene': [['Ristorante', 'Piatto'], ['Piatto', 'Ingrediente']], 'preparato': [['Piatto', 'Tecnica']], 'situato': [['Ristorante', 'Pianeta']], 'possiede': [['Ristorante', 'Licenza']]}\n"
     ]
    }
   ],
   "source": [
    "# Esegui l'analisi del PDF\n",
    "testo_menu = estrai_testo_pdf(menu_esempio)\n",
    "entita_menu = estrai_relazioni(testo=testo_menu, categorie=entita_filtrate, llm=llm)\n",
    "print(\"Entità PDF:\", entita_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità PDF: {'Ristorante': 35.0, 'Piatti': 25.0, 'Ingrediente': 20.0, 'Chef': 10.0, 'Tecnica': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Esempio di utilizzo:\n",
    "testo_blog1 = estrai_testo_html(blog_1)\n",
    "entita_blog1 = estrai_schema(testo=testo_blog1, llm=llm)\n",
    "print(\"Entità PDF:\", entita_blog1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entità PDF: {'Ristorante': 30.0, 'Ingrediente': 25.0, 'Piatto': 20.0, 'Tecnica': 10.0, 'Chef': 5.0, 'Pianeta': 5.0, 'Critico': 3.0, 'Voto': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Esempio di utilizzo:\n",
    "testo_blog2 = estrai_testo_html(blog_2)\n",
    "entita_blog2 = estrai_schema(testo=testo_blog2, llm=llm)\n",
    "print(\"Entità PDF:\", entita_blog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punteggi combinati: {'Sostanza': 30.0, 'Tecnica': 26.25, 'Licenza': 22.75, 'Ordine': 10.0, 'Ingrediente': 28.125, 'Piatto': 40.0, 'Ristorante': 29.0, 'Pianeta': 40.0, 'Cottura': 15.0, 'Preparazione': 8.0, 'Galassia': 5.0, 'Menu': 12.0, 'Chef': 8.333333333333334, 'Critico': 3.0, 'Voto': 2.0}\n"
     ]
    }
   ],
   "source": [
    "json_list = [entita_codice, entita_domande, entita_manuale, entita_menu, entita_pianeti, entita_blog1, entita_blog2]\n",
    "punteggi_combinati = combina_punteggi(json_list, llm)\n",
    "print(\"Punteggi combinati:\", punteggi_combinati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sostanza', 'Tecnica', 'Licenza', 'Ordine', 'Ingrediente', 'Piatto', 'Ristorante', 'Pianeta', 'Cottura', 'Menu']\n"
     ]
    }
   ],
   "source": [
    "# Filtra le entità con punteggio superiore a 20\n",
    "entita_filtrate = [entita for entita, punteggio in punteggi_combinati.items() if punteggio >= 10]\n",
    "\n",
    "print(entita_filtrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m entita_filtrate\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSostanza\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mentita_filtrate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMenu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m entita_filtrate\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCottura\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "entita_filtrate.remove('Sostanza')\n",
    "entita_filtrate.remove('Menu')\n",
    "entita_filtrate.remove('Cottura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('entita_filtrate.txt', 'w') as file:\n",
    "    for entita in entita_filtrate:\n",
    "        file.write(f\"{entita}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
